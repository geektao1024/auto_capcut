# Whisper + CapCut å­—å¹•ç‰¹æ•ˆå®ç°æ–¹æ¡ˆ

## ğŸ¯ éœ€æ±‚åˆ†æ

1. **å•è¯é€ä¸ªå¼¹å‡ºæ•ˆæœ** 
   - æ¯ä¸ªå•è¯å•ç‹¬æ˜¾ç¤º
   - å¸¦å…¥åœºåŠ¨ç”»ï¼ˆå¼¹å‡º/æ·¡å…¥ï¼‰

2. **å­—å¹•æ ·å¼è‡ªå®šä¹‰**
   - é¢œè‰²ï¼ˆRGBï¼‰
   - æè¾¹ï¼ˆå®½åº¦ã€é¢œè‰²ï¼‰
   - å­—å·
   - å­—ä½“

## âœ… æŠ€æœ¯å¯è¡Œæ€§

### 1. Whisper Word-Level Timestamps

```python
import whisper

model = whisper.load_model("base")
result = model.transcribe(
    "audio.mp3",
    language="en",
    word_timestamps=True  # â­ å¯ç”¨å•è¯çº§æ—¶é—´æˆ³
)

# è¾“å‡ºç¤ºä¾‹
{
  "segments": [
    {
      "text": "The little girl walked into the house",
      "words": [
        {"word": "The", "start": 0.0, "end": 0.18},
        {"word": "little", "start": 0.18, "end": 0.42},
        {"word": "girl", "start": 0.42, "end": 0.68},
        {"word": "walked", "start": 0.68, "end": 1.02},
        ...
      ]
    }
  ]
}
```

âœ… **ä¼˜ç‚¹**ï¼š
- ç²¾ç¡®çš„å•è¯æ—¶é—´æˆ³ï¼ˆç²¾åº¦çº¦0.02ç§’ï¼‰
- è‡ªåŠ¨åˆ†è¯ï¼Œæ”¯æŒå¤šè¯­è¨€
- å¼€æºå…è´¹ï¼Œæœ¬åœ°è¿è¡Œ

### 2. CapCutå­—å¹•æ ·å¼æ§åˆ¶

#### textsææ–™ç»“æ„
```json
{
  "id": "UUID",
  "content": "å•è¯å†…å®¹",
  "fonts": [
    {
      "id": "",
      "name": "SourceHanSansCN-Bold",  // å­—ä½“åç§°
      "path": ""
    }
  ],
  "styles": [
    {
      "fill": {
        "alpha": 1.0,
        "content": {
          "solid": {
            "color": [1.0, 1.0, 0.0]  // â­ RGBé¢œè‰²ï¼ˆé»„è‰²ï¼‰
          }
        }
      },
      "range": [0, 4],  // åº”ç”¨åˆ°æ•´ä¸ªå•è¯
      "size": 20.0,  // â­ å­—å·
      "stroke": {
        "alpha": 1.0,
        "width": 0.3,  // â­ æè¾¹å®½åº¦
        "content": {
          "solid": {
            "color": [0.0, 0.0, 0.0]  // â­ æè¾¹é¢œè‰²ï¼ˆé»‘è‰²ï¼‰
          }
        }
      }
    }
  ],
  "type": "caption",
  "alignment": 1,  // 0=å·¦å¯¹é½, 1=å±…ä¸­, 2=å³å¯¹é½
  "line_spacing": 0.0,
  "bold": true,  // ç²—ä½“
  "italic": false  // æ–œä½“
}
```

âœ… **å®Œå…¨å¯æ§åˆ¶**ï¼š
- âœ… é¢œè‰²ï¼š`fill.content.solid.color` (RGB 0-1èŒƒå›´)
- âœ… æè¾¹ï¼š`stroke.width` å’Œ `stroke.content.solid.color`
- âœ… å­—å·ï¼š`size`
- âœ… å­—ä½“ï¼š`fonts[0].name`
- âœ… å¯¹é½ï¼š`alignment`

### 3. å­—å¹•åŠ¨ç”»æ•ˆæœ

#### æ–¹æ¡ˆA: ä½¿ç”¨material_animationsï¼ˆå…¥åœºåŠ¨ç”»ï¼‰â­ æ¨è

```json
{
  "materials": {
    "material_animations": [
      {
        "animations": [{
          "anim_adjust_params": null,
          "category_id": "in",
          "category_name": "å…¥åœº",
          "duration": 200000,  // 0.2ç§’åŠ¨ç”»æ—¶é•¿
          "id": "431664",  // åŠ¨ç”»ID
          "material_type": "text",  // â­ å­—å¹•åŠ¨ç”»
          "name": "å‘ä¸Šå¼¹å…¥",  // æˆ–"æ·¡å…¥"ã€"æ”¾å¤§"ç­‰
          "panel": "text",
          "path": "ç‰¹æ•ˆèµ„æºè·¯å¾„",
          "type": "in",
          "start": 0
        }],
        "id": "UUID",
        "type": "sticker_animation"
      }
    ]
  }
}
```

ç„¶ååœ¨text segmentä¸­å¼•ç”¨ï¼š
```json
{
  "material_id": "å­—å¹•material_id",
  "extra_material_refs": [
    "åŠ¨ç”»material_id"  // â­ å¼•ç”¨åŠ¨ç”»
  ]
}
```

#### æ–¹æ¡ˆB: ä½¿ç”¨caption_infoï¼ˆå­—å¹•ç‰¹æœ‰åŠ¨ç”»ï¼‰

```json
{
  "caption_info": {
    "animations": {
      "in": {
        "type": "bounce",  // å¼¹è·³
        "duration": 200000
      }
    }
  }
}
```

## ğŸ”§ å®Œæ•´å®ç°æ–¹æ¡ˆ

### æ­¥éª¤1: å®‰è£…Whisper

```bash
pip install openai-whisper
```

### æ­¥éª¤2: è¯†åˆ«éŸ³é¢‘è·å–å•è¯æ—¶é—´æˆ³

```python
import whisper

def transcribe_with_word_timestamps(audio_file, language="en"):
    """ä½¿ç”¨Whisperè¯†åˆ«éŸ³é¢‘ï¼Œè¿”å›å•è¯çº§æ—¶é—´æˆ³"""
    
    model = whisper.load_model("base")
    result = model.transcribe(
        audio_file,
        language=language,
        word_timestamps=True,
        verbose=False
    )
    
    # å±•å¹³æ‰€æœ‰å•è¯
    words = []
    for segment in result["segments"]:
        for word in segment.get("words", []):
            words.append({
                "text": word["word"].strip(),
                "start": word["start"],
                "end": word["end"]
            })
    
    return words

# ä½¿ç”¨
words = transcribe_with_word_timestamps("audio.mp3", "en")
# [
#   {"text": "The", "start": 0.0, "end": 0.18},
#   {"text": "little", "start": 0.18, "end": 0.42},
#   ...
# ]
```

### æ­¥éª¤3: ç”Ÿæˆå­—å¹•ææ–™å’Œè½¨é“

```python
def create_word_subtitles(words, draft, config):
    """ä¸ºæ¯ä¸ªå•è¯åˆ›å»ºå­—å¹•ææ–™å’Œç‰‡æ®µ"""
    
    # å­—å¹•é…ç½®ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    SUBTITLE_CONFIG = {
        "font_size": 20.0,
        "color": [1.0, 1.0, 0.0],  # é»„è‰²
        "stroke_width": 0.3,
        "stroke_color": [0.0, 0.0, 0.0],  # é»‘è‰²æè¾¹
        "alignment": 1,  # å±…ä¸­
        "animation": "bounce"  # å¼¹è·³å…¥åœº
    }
    
    texts = []
    text_segments = []
    
    for word_data in words:
        word = word_data["text"]
        start = int(word_data["start"] * 1000000)  # è½¬ä¸ºå¾®ç§’
        end = int(word_data["end"] * 1000000)
        duration = end - start
        
        # 1. åˆ›å»ºå­—å¹•ææ–™
        text_id = str(uuid.uuid4()).upper()
        text_material = {
            "id": text_id,
            "content": word,
            "fonts": [{
                "id": "",
                "name": "SourceHanSansCN-Bold",
                "path": ""
            }],
            "styles": [{
                "fill": {
                    "alpha": 1.0,
                    "content": {
                        "solid": {
                            "color": SUBTITLE_CONFIG["color"]
                        }
                    }
                },
                "range": [0, len(word)],
                "size": SUBTITLE_CONFIG["font_size"],
                "stroke": {
                    "alpha": 1.0,
                    "width": SUBTITLE_CONFIG["stroke_width"],
                    "content": {
                        "solid": {
                            "color": SUBTITLE_CONFIG["stroke_color"]
                        }
                    }
                }
            }],
            "type": "caption",
            "alignment": SUBTITLE_CONFIG["alignment"],
            "line_spacing": 0.0
        }
        texts.append(text_material)
        
        # 2. åˆ›å»ºå­—å¹•ç‰‡æ®µ
        text_segment = {
            "id": str(uuid.uuid4()).upper(),
            "material_id": text_id,
            "target_timerange": {
                "start": start,
                "duration": duration
            },
            "source_timerange": {
                "start": 0,
                "duration": duration
            },
            "extra_material_refs": [],  # å¯ä»¥æ·»åŠ åŠ¨ç”»å¼•ç”¨
            "caption_info": None,
            "visible": True
        }
        text_segments.append(text_segment)
    
    return texts, text_segments
```

### æ­¥éª¤4: æ·»åŠ å…¥åœºåŠ¨ç”»ï¼ˆå¯é€‰ï¼‰

```python
def create_bounce_animation():
    """åˆ›å»ºå¼¹è·³å…¥åœºåŠ¨ç”»"""
    
    animation_id = str(uuid.uuid4()).upper()
    animation = {
        "animations": [{
            "anim_adjust_params": None,
            "category_id": "in",
            "category_name": "å…¥åœº",
            "duration": 200000,  # 0.2ç§’
            "id": "text_bounce",
            "material_type": "text",
            "name": "å‘ä¸Šå¼¹å…¥",
            "panel": "text",
            "path": "",
            "type": "in",
            "start": 0
        }],
        "id": animation_id,
        "type": "sticker_animation"
    }
    
    return animation_id, animation
```

### æ­¥éª¤5: é›†æˆåˆ°è‰ç¨¿ç”Ÿæˆ

```python
def create_capcut_draft_with_subtitles(audio_file, images, output_dir):
    """ç”Ÿæˆå¸¦å­—å¹•çš„CapCutè‰ç¨¿"""
    
    # 1. Whisperè¯†åˆ«
    print("ğŸ¤ è¯†åˆ«éŸ³é¢‘...")
    words = transcribe_with_word_timestamps(audio_file, language="en")
    print(f"âœ… è¯†åˆ«åˆ° {len(words)} ä¸ªå•è¯")
    
    # 2. åˆ›å»ºåŸºç¡€è‰ç¨¿
    draft = create_base_draft(audio_file, images)
    
    # 3. æ·»åŠ å­—å¹•
    print("ğŸ“ ç”Ÿæˆå­—å¹•...")
    texts, text_segments = create_word_subtitles(words, draft, config)
    
    draft['materials']['texts'] = texts
    
    # 4. åˆ›å»ºå­—å¹•è½¨é“
    text_track = {
        "type": "text",
        "flag": 0,  # 0=æ‰‹åŠ¨æ·»åŠ ï¼ˆè„šæœ¬ç”Ÿæˆï¼‰
        "attribute": 0,
        "id": str(uuid.uuid4()).upper(),
        "segments": text_segments
    }
    
    draft['tracks'].append(text_track)
    
    # 5. ä¿å­˜è‰ç¨¿
    save_draft(draft, output_dir)
    
    print(f"âœ… è‰ç¨¿åˆ›å»ºå®Œæˆï¼åŒ…å« {len(words)} ä¸ªå•è¯å­—å¹•")
```

## ğŸ¨ æ ·å¼è‡ªå®šä¹‰é…ç½®

### é¢„è®¾æ ·å¼æ¨¡æ¿

```python
# é…ç½®æ–‡ä»¶é¡¶éƒ¨
SUBTITLE_STYLES = {
    "é»˜è®¤": {
        "font_size": 20.0,
        "color": [1.0, 1.0, 1.0],  # ç™½è‰²
        "stroke_width": 0.3,
        "stroke_color": [0.0, 0.0, 0.0]  # é»‘è‰²æè¾¹
    },
    "é»„è‰²çªå‡º": {
        "font_size": 22.0,
        "color": [1.0, 1.0, 0.0],  # é»„è‰²
        "stroke_width": 0.4,
        "stroke_color": [0.0, 0.0, 0.0]
    },
    "çº¢è‰²å¼ºè°ƒ": {
        "font_size": 24.0,
        "color": [1.0, 0.2, 0.2],  # çº¢è‰²
        "stroke_width": 0.5,
        "stroke_color": [1.0, 1.0, 1.0]  # ç™½è‰²æè¾¹
    }
}

# ä½¿ç”¨
SUBTITLE_CONFIG = SUBTITLE_STYLES["é»„è‰²çªå‡º"]
```

## ğŸ“Š æ•ˆæœå¯¹æ¯”

| åŠŸèƒ½ | CapCutæ‰‹åŠ¨è¯†åˆ« | Whisperè„šæœ¬ç”Ÿæˆ |
|------|--------------|----------------|
| å•è¯æ—¶é—´æˆ³ | âœ… è‡ªåŠ¨ | âœ… è‡ªåŠ¨ï¼ˆword_timestampsï¼‰ |
| å•è¯é€ä¸ªå¼¹å‡º | âœ… æ”¯æŒ | âœ… å®Œå…¨å¯å®ç° |
| é¢œè‰²è‡ªå®šä¹‰ | âœ… UIè°ƒæ•´ | âœ… ä»£ç é…ç½® |
| æè¾¹æ§åˆ¶ | âœ… UIè°ƒæ•´ | âœ… ä»£ç é…ç½® |
| å…¥åœºåŠ¨ç”» | âœ… ä¸°å¯Œ | âš ï¸ éœ€ç ”ç©¶åŠ¨ç”»ID |
| å‡†ç¡®åº¦ | â­â­â­â­â­ | â­â­â­â­ (æ¥è¿‘) |
| è‡ªåŠ¨åŒ–ç¨‹åº¦ | â­â­ (éœ€æ‰‹åŠ¨ç‚¹å‡») | â­â­â­â­â­ (å…¨è‡ªåŠ¨) |

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. åŠ¨ç”»æ•ˆæœé™åˆ¶

**ç®€å•å…¥åœºåŠ¨ç”»** âœ… å¯å®ç°ï¼š
- æ·¡å…¥ï¼ˆopacityå˜åŒ–ï¼‰
- ä½ç½®ç§»åŠ¨ï¼ˆä»ä¸‹å‘ä¸Šï¼‰

**å¤æ‚åŠ¨ç”»** âš ï¸ éœ€ç ”ç©¶ï¼š
- å¼¹è·³æ•ˆæœï¼ˆéœ€è¦CapCutç‰¹å®šçš„åŠ¨ç”»èµ„æºï¼‰
- æ—‹è½¬ã€ç¼©æ”¾ï¼ˆéœ€è¦æ‰¾åˆ°å¯¹åº”çš„åŠ¨ç”»IDï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å…ˆå®ç°åŸºç¡€æ ·å¼ï¼ˆé¢œè‰²ã€æè¾¹ï¼‰âœ…
2. ä½¿ç”¨ç®€å•çš„æ·¡å…¥æ•ˆæœ âœ…
3. å¦‚éœ€å¤æ‚åŠ¨ç”»ï¼Œç”¨æˆ·å¯åœ¨CapCutä¸­æ‰‹åŠ¨æ·»åŠ 

### 2. æ€§èƒ½è€ƒè™‘

```python
# Whisperæ¨¡å‹å¤§å°é€‰æ‹©
models = {
    "tiny": "æœ€å¿«ï¼Œå‡†ç¡®åº¦è¾ƒä½",
    "base": "æ¨èï¼Œé€Ÿåº¦å’Œå‡†ç¡®åº¦å¹³è¡¡",  # â­
    "small": "è¾ƒå‡†ç¡®ï¼Œç¨æ…¢",
    "medium": "å¾ˆå‡†ç¡®ï¼Œè¾ƒæ…¢",
    "large": "æœ€å‡†ç¡®ï¼Œæœ€æ…¢"
}

# å¯¹äºè‹±æ–‡çŸ­è§†é¢‘ï¼ˆ<1åˆ†é’Ÿï¼‰ï¼Œbaseæ¨¡å‹å³å¯
model = whisper.load_model("base")
```

### 3. ä¸­æ–‡æ”¯æŒ

```python
# ä¸­æ–‡è¯†åˆ«
result = model.transcribe(
    audio_file,
    language="zh",  # ä¸­æ–‡
    word_timestamps=True
)

# æ³¨æ„ï¼šä¸­æ–‡çš„word_timestampså¯èƒ½æŒ‰å­—åˆ†ï¼Œä¸æ˜¯æŒ‰è¯
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ€å°å¯è¡Œæ–¹æ¡ˆï¼ˆMVPï¼‰

```python
# 1. å®‰è£…
pip install openai-whisper

# 2. åŸºç¡€å®ç°ï¼ˆ20è¡Œä»£ç ï¼‰
import whisper

model = whisper.load_model("base")
result = model.transcribe("audio.mp3", word_timestamps=True)

# æå–æ‰€æœ‰å•è¯
words = []
for seg in result["segments"]:
    words.extend(seg.get("words", []))

# ç”Ÿæˆå­—å¹•ï¼ˆç®€åŒ–ç‰ˆï¼‰
for word in words:
    print(f'{word["word"]}: {word["start"]:.2f}s - {word["end"]:.2f}s')
```

## âœ… ç»“è®º

**å®Œå…¨å¯è¡Œï¼** âœ…

1. **å•è¯æ—¶é—´æˆ³**: Whisperçš„word_timestampsåŠŸèƒ½å®Œç¾æ”¯æŒ
2. **æ ·å¼æ§åˆ¶**: CapCutçš„textsææ–™ç»“æ„å®Œå…¨å¯ç¼–ç¨‹æ§åˆ¶
   - âœ… é¢œè‰²
   - âœ… æè¾¹
   - âœ… å­—å·
   - âœ… å­—ä½“
3. **é€è¯å¼¹å‡º**: ä¸ºæ¯ä¸ªå•è¯åˆ›å»ºç‹¬ç«‹çš„å­—å¹•ç‰‡æ®µå³å¯å®ç°
4. **å…¥åœºåŠ¨ç”»**: åŸºç¡€åŠ¨ç”»å¯å®ç°ï¼Œå¤æ‚åŠ¨ç”»éœ€è¿›ä¸€æ­¥ç ”ç©¶

**å»ºè®®å®æ–½æ­¥éª¤**ï¼š
1. âœ… å…ˆå®ç°åŸºç¡€ç‰ˆï¼ˆå•è¯å­—å¹• + æ ·å¼è‡ªå®šä¹‰ï¼‰
2. âœ… æµ‹è¯•æ•ˆæœ
3. âš ï¸ å¦‚éœ€ç‰¹å®šåŠ¨ç”»ï¼Œåˆ†æCapCutç°æœ‰åŠ¨ç”»ç»“æ„
4. âœ… é€æ­¥å®Œå–„

---

**è¦ä¸è¦ç°åœ¨å°±å¼€å§‹é›†æˆWhisperï¼Ÿ** ğŸš€

