# æ–¹æ¡ˆ Aï¼šæ™ºèƒ½å£æ’­è§†é¢‘è‡ªåŠ¨ç”Ÿæˆæ–¹æ¡ˆ

## ğŸ“‹ éœ€æ±‚æ¦‚è¿°

**æ ¸å¿ƒéœ€æ±‚ï¼š**
1. å¤„ç† ElevenLabs ç”Ÿæˆçš„è‹±æ–‡éŸ³é¢‘ï¼ˆå«é—´éš™ï¼‰
2. è‡ªåŠ¨ç§»é™¤éŸ³é¢‘ä¸­çš„é™éŸ³ç‰‡æ®µ
3. è‹±æ–‡è¯­éŸ³è¯†åˆ« + è‡ªåŠ¨ç”Ÿæˆå­—å¹•
4. å›¾ç‰‡æŒ‰å£æ’­æ™ºèƒ½åˆ†å¸ƒåˆ°æ—¶é—´çº¿
5. ç”Ÿæˆ 16:9 (1920x1080) è§†é¢‘

**è¾“å…¥ææ–™ï¼š**
- ğŸµ è‹±æ–‡éŸ³é¢‘æ–‡ä»¶ï¼ˆMP3/WAVï¼‰
- ğŸ–¼ï¸ å¤šå¼ å›¾ç‰‡ï¼ˆPNG/JPGï¼‰

**è¾“å‡ºç»“æœï¼š**
- ğŸ“¹ 16:9 è§†é¢‘ï¼ˆMP4ï¼‰
- ğŸ“ SRT å­—å¹•æ–‡ä»¶

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### æŠ€æœ¯æ ˆ

```
æ ¸å¿ƒåº“ï¼š
â”œâ”€â”€ pydub (éŸ³é¢‘å¤„ç†)
â”œâ”€â”€ whisper (è¯­éŸ³è¯†åˆ«)
â”œâ”€â”€ moviepy (è§†é¢‘åˆæˆ)
â”œâ”€â”€ mutagen (éŸ³é¢‘å…ƒæ•°æ®)
â””â”€â”€ ffmpeg (åº•å±‚å¼•æ“)

è¾…åŠ©åº“ï¼š
â”œâ”€â”€ glob (æ–‡ä»¶åŒ¹é…)
â”œâ”€â”€ re (æ­£åˆ™æ’åº)
â””â”€â”€ uuid (å”¯ä¸€IDç”Ÿæˆ)
```

### å¤„ç†æµç¨‹

```
è¾“å…¥éŸ³é¢‘ â†’ ç§»é™¤é™éŸ³ â†’ è¯­éŸ³è¯†åˆ« â†’ ç”Ÿæˆå­—å¹•
    â†“           â†“          â†“           â†“
  å›¾ç‰‡æ’åº â†’ æ™ºèƒ½åˆ†é… â†’ åˆæˆè§†é¢‘ â†’ è¾“å‡ºMP4
```

---

## ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹

### ä» `zidongjianji.py` å€Ÿé‰´çš„æ™ºèƒ½é€»è¾‘

#### 1. ç²¾å‡†éŸ³é¢‘æ—¶é•¿æ£€æµ‹
```python
# ä½¿ç”¨ mutagen åº“è·å–å¾®ç§’çº§ç²¾åº¦
def get_audio_duration_accurate(audio_file: str) -> float:
    audio = MutagenFile(audio_file)
    return audio.info.length  # ç§’
```

#### 2. çŸ­éŸ³é¢‘ vs é•¿éŸ³é¢‘çš„æ™ºèƒ½åˆ†é…
```
åˆ¤æ–­é€»è¾‘ï¼ˆé˜ˆå€¼ï¼š1.5ç§’ï¼‰ï¼š

çŸ­éŸ³é¢‘ï¼ˆ< 1.5sï¼‰ï¼š
â”œâ”€â”€ é…1å¼ å›¾ç‰‡
â”œâ”€â”€ å›¾ç‰‡æ˜¾ç¤ºå®Œæ•´éŸ³é¢‘æ—¶é•¿
â””â”€â”€ é€‚ç”¨åœºæ™¯ï¼šåœé¡¿ã€è¿‡æ¸¡å¥

é•¿éŸ³é¢‘ï¼ˆâ‰¥ 1.5sï¼‰ï¼š
â”œâ”€â”€ é…2å¼ å›¾ç‰‡
â”œâ”€â”€ å¹³å‡åˆ†é…æ—¶é—´ï¼ˆå„å ä¸€åŠï¼‰
â””â”€â”€ é€‚ç”¨åœºæ™¯ï¼šå®Œæ•´å¥å­ã€æ®µè½
```

#### 3. è‡ªç„¶æ’åº
```python
# ç¡®ä¿æ–‡ä»¶æŒ‰ 1-1, 1-2, 1-3 è€Œä¸æ˜¯ 1-1, 1-10, 1-11
def natural_sort_key(filename: str) -> tuple:
    parts = re.findall(r'(\d+)', filename)
    return tuple(int(part) for part in parts)
```

---

## ğŸ“¦ å®Œæ•´ä»£ç å®ç°

### ä¸»ç¨‹åºï¼š`auto_video_generator.py`

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å£æ’­è§†é¢‘è‡ªåŠ¨ç”Ÿæˆå™¨
èåˆ zidongjianji.py çš„æ™ºèƒ½åˆ†é…é€»è¾‘ + å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹
"""

import os
import glob
import re
from typing import List, Tuple
from pydub import AudioSegment
from pydub.silence import detect_nonsilent
import whisper
from moviepy.editor import *
from mutagen import File as MutagenFile

# ============================================================================
# å·¥å…·å‡½æ•°ï¼ˆå€Ÿé‰´ zidongjianji.pyï¼‰
# ============================================================================

def natural_sort_key(filename: str) -> tuple:
    """
    è‡ªç„¶æ’åºé”®å‡½æ•°ï¼Œç¡®ä¿ 1-1, 1-2, 1-3 è€Œä¸æ˜¯ 1-1, 1-10, 1-11
    å€Ÿé‰´è‡ª zidongjianji.py ç¬¬20-26è¡Œ
    """
    parts = re.findall(r'(\d+)', filename)
    return tuple(int(part) for part in parts)


def get_audio_duration_accurate(audio_file: str) -> float:
    """
    è·å–éŸ³é¢‘æ–‡ä»¶çš„ç²¾ç¡®æ—¶é•¿ï¼ˆç§’ï¼‰
    å€Ÿé‰´è‡ª zidongjianji.py ç¬¬28-43è¡Œ
    """
    try:
        audio = MutagenFile(audio_file)
        if audio is not None and hasattr(audio, 'info') and hasattr(audio.info, 'length'):
            return audio.info.length
        else:
            print(f"âš ï¸  æ— æ³•è¯»å–éŸ³é¢‘æ—¶é•¿: {os.path.basename(audio_file)}")
            return 3.0  # é»˜è®¤3ç§’
    except Exception as e:
        print(f"âš ï¸  è¯»å–éŸ³é¢‘æ—¶é•¿å‡ºé”™ {os.path.basename(audio_file)}: {e}")
        return 3.0


# ============================================================================
# éŸ³é¢‘å¤„ç†æ¨¡å—
# ============================================================================

def remove_silence(input_audio: str, output_audio: str) -> str:
    """
    ç§»é™¤éŸ³é¢‘ä¸­çš„é™éŸ³ç‰‡æ®µ
    
    Args:
        input_audio: è¾“å…¥éŸ³é¢‘è·¯å¾„
        output_audio: è¾“å‡ºéŸ³é¢‘è·¯å¾„
        
    Returns:
        å¤„ç†åçš„éŸ³é¢‘è·¯å¾„
    """
    print(f"\nğŸµ æ­£åœ¨å¤„ç†éŸ³é¢‘: {os.path.basename(input_audio)}")
    
    audio = AudioSegment.from_file(input_audio)
    original_duration = len(audio) / 1000  # æ¯«ç§’è½¬ç§’
    
    # æ£€æµ‹éé™éŸ³ç‰‡æ®µ
    # min_silence_len: æœ€å°é™éŸ³é•¿åº¦ï¼ˆæ¯«ç§’ï¼‰ï¼Œä½äºæ­¤å€¼çš„é™éŸ³ä¼šè¢«ä¿ç•™
    # silence_thresh: é™éŸ³é˜ˆå€¼ï¼ˆdBï¼‰ï¼Œä½äºæ­¤å€¼è§†ä¸ºé™éŸ³
    nonsilent_ranges = detect_nonsilent(
        audio,
        min_silence_len=500,    # 500ms ä»¥ä¸Šçš„é™éŸ³æ‰ä¼šè¢«ç§»é™¤
        silence_thresh=-40,     # -40dB ä»¥ä¸‹è§†ä¸ºé™éŸ³
        seek_step=10            # æ£€æµ‹æ­¥é•¿ï¼ˆæ¯«ç§’ï¼‰
    )
    
    # æ‹¼æ¥æ‰€æœ‰éé™éŸ³ç‰‡æ®µ
    output = AudioSegment.empty()
    for start, end in nonsilent_ranges:
        output += audio[start:end]
    
    # å¯¼å‡ºå¤„ç†åçš„éŸ³é¢‘
    output.export(output_audio, format="mp3")
    
    new_duration = len(output) / 1000
    removed_duration = original_duration - new_duration
    
    print(f"âœ… é™éŸ³ç§»é™¤å®Œæˆ")
    print(f"   åŸæ—¶é•¿: {original_duration:.2f}ç§’")
    print(f"   æ–°æ—¶é•¿: {new_duration:.2f}ç§’")
    print(f"   ç§»é™¤: {removed_duration:.2f}ç§’ ({removed_duration/original_duration*100:.1f}%)")
    
    return output_audio


# ============================================================================
# è¯­éŸ³è¯†åˆ« + å­—å¹•ç”Ÿæˆæ¨¡å—
# ============================================================================

def generate_subtitles(audio_path: str, srt_path: str) -> List[dict]:
    """
    ä½¿ç”¨ Whisper è¯†åˆ«è‹±æ–‡å¹¶ç”Ÿæˆ SRT å­—å¹•
    
    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        srt_path: è¾“å‡º SRT æ–‡ä»¶è·¯å¾„
        
    Returns:
        å­—å¹•ç‰‡æ®µåˆ—è¡¨ï¼ˆåŒ…å«æ—¶é—´æˆ³å’Œæ–‡æœ¬ï¼‰
    """
    print(f"\nğŸ¤ æ­£åœ¨è¯†åˆ«è‹±æ–‡è¯­éŸ³...")
    
    # åŠ è½½ Whisper æ¨¡å‹
    # å¯é€‰: tiny, base, small, medium, large
    # base æ¨¡å‹çº¦ 140MBï¼Œè¯†åˆ«é€Ÿåº¦å¿«ï¼Œå‡†ç¡®åº¦é€‚ä¸­
    model = whisper.load_model("base")
    
    # è½¬å½•éŸ³é¢‘
    result = model.transcribe(audio_path, language="en", verbose=True)
    
    # ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
    with open(srt_path, "w", encoding="utf-8") as f:
        for i, segment in enumerate(result['segments'], 1):
            start = format_timestamp(segment['start'])
            end = format_timestamp(segment['end'])
            text = segment['text'].strip()
            
            f.write(f"{i}\n")
            f.write(f"{start} --> {end}\n")
            f.write(f"{text}\n\n")
    
    print(f"âœ… å­—å¹•ç”Ÿæˆå®Œæˆ")
    print(f"   è¯†åˆ«åˆ° {len(result['segments'])} ä¸ªå¥å­")
    print(f"   å­—å¹•æ–‡ä»¶: {srt_path}")
    
    return result['segments']


def format_timestamp(seconds: float) -> str:
    """
    è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)
    
    Args:
        seconds: æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        SRT æ ¼å¼æ—¶é—´å­—ç¬¦ä¸²
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


# ============================================================================
# è§†é¢‘åˆæˆæ¨¡å—ï¼ˆæ ¸å¿ƒï¼šæ™ºèƒ½å›¾ç‰‡åˆ†é…ï¼‰
# ============================================================================

def create_video_with_smart_distribution(
    audio_path: str,
    image_folder: str,
    srt_path: str,
    output_path: str,
    segments: List[dict] = None,
    duration_threshold: float = 1.5
) -> None:
    """
    åˆ›å»ºè§†é¢‘ï¼Œä½¿ç”¨æ™ºèƒ½å›¾ç‰‡åˆ†é…é€»è¾‘
    
    å€Ÿé‰´ zidongjianji.py ç¬¬316-492è¡Œçš„æ ¸å¿ƒé€»è¾‘ï¼š
    - çŸ­éŸ³é¢‘æ®µï¼ˆ< 1.5ç§’ï¼‰ï¼šé…1å¼ å›¾ç‰‡
    - é•¿éŸ³é¢‘æ®µï¼ˆâ‰¥ 1.5ç§’ï¼‰ï¼šé…2å¼ å›¾ç‰‡ï¼Œå¹³å‡åˆ†é…æ—¶é—´
    
    Args:
        audio_path: å¤„ç†åçš„éŸ³é¢‘è·¯å¾„
        image_folder: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        srt_path: å­—å¹•æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        segments: è¯­éŸ³è¯†åˆ«çš„ç‰‡æ®µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        duration_threshold: çŸ­/é•¿éŸ³é¢‘çš„æ—¶é•¿é˜ˆå€¼ï¼ˆç§’ï¼‰
    """
    print(f"\nğŸ¬ æ­£åœ¨åˆæˆè§†é¢‘...")
    
    # 1. åŠ è½½éŸ³é¢‘
    audio = AudioFileClip(audio_path)
    total_duration = audio.duration
    
    # 2. å¦‚æœæ²¡æœ‰æä¾› segmentsï¼Œé‡æ–°è¯†åˆ«
    if segments is None:
        temp_srt = "temp_subtitles.srt"
        segments = generate_subtitles(audio_path, temp_srt)
    
    # 3. è·å–æ‰€æœ‰å›¾ç‰‡å¹¶è‡ªç„¶æ’åº
    image_files = []
    for ext in ['*.png', '*.jpg', '*.jpeg', '*.PNG', '*.JPG', '*.JPEG']:
        image_files.extend(glob.glob(os.path.join(image_folder, ext)))
    
    if not image_files:
        raise ValueError(f"âŒ åœ¨ {image_folder} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
    
    # ä½¿ç”¨è‡ªç„¶æ’åº
    image_files.sort(key=lambda x: natural_sort_key(os.path.basename(x)))
    
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"   è¯†åˆ«åˆ° {len(segments)} ä¸ªå¥å­")
    
    # 4. æ™ºèƒ½åˆ†é…å›¾ç‰‡ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰
    clips = []
    image_index = 0
    
    print(f"\n=== æ™ºèƒ½å›¾ç‰‡åˆ†é…ï¼ˆé˜ˆå€¼: {duration_threshold}ç§’ï¼‰===")
    
    for i, segment in enumerate(segments):
        start_time = segment['start']
        end_time = segment['end']
        duration = end_time - start_time
        text = segment['text'].strip()
        
        # åˆ¤æ–­æ˜¯çŸ­éŸ³é¢‘è¿˜æ˜¯é•¿éŸ³é¢‘
        if duration < duration_threshold:
            # ========== çŸ­éŸ³é¢‘ï¼šé…1å¼ å›¾ç‰‡ ==========
            if image_index < len(image_files):
                img_path = image_files[image_index]
                
                img_clip = (ImageClip(img_path)
                           .set_start(start_time)
                           .set_duration(duration)
                           .resize(height=1080)  # ä¿æŒå®½é«˜æ¯”ï¼Œé«˜åº¦1080
                           .set_position("center"))
                
                clips.append(img_clip)
                
                print(f"å¥å­ {i+1} (çŸ­éŸ³é¢‘ {duration:.2f}s): å›¾ç‰‡ {image_index+1}")
                print(f"  â””â”€ \"{text[:50]}...\"" if len(text) > 50 else f"  â””â”€ \"{text}\"")
                
                image_index += 1
            else:
                print(f"âš ï¸  å¥å­ {i+1} æ— å¯ç”¨å›¾ç‰‡")
        
        else:
            # ========== é•¿éŸ³é¢‘ï¼šé…2å¼ å›¾ç‰‡ ==========
            if image_index + 1 < len(image_files):
                half_duration = duration / 2
                
                # ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆå‰åŠæ®µï¼‰
                img1_path = image_files[image_index]
                img1_clip = (ImageClip(img1_path)
                            .set_start(start_time)
                            .set_duration(half_duration)
                            .resize(height=1080)
                            .set_position("center"))
                clips.append(img1_clip)
                
                # ç¬¬äºŒå¼ å›¾ç‰‡ï¼ˆååŠæ®µï¼‰
                img2_path = image_files[image_index + 1]
                img2_clip = (ImageClip(img2_path)
                            .set_start(start_time + half_duration)
                            .set_duration(duration - half_duration)
                            .resize(height=1080)
                            .set_position("center"))
                clips.append(img2_clip)
                
                print(f"å¥å­ {i+1} (é•¿éŸ³é¢‘ {duration:.2f}s): å›¾ç‰‡ {image_index+1} ({half_duration:.2f}s) + å›¾ç‰‡ {image_index+2} ({duration-half_duration:.2f}s)")
                print(f"  â””â”€ \"{text[:50]}...\"" if len(text) > 50 else f"  â””â”€ \"{text}\"")
                
                image_index += 2
            else:
                print(f"âš ï¸  å¥å­ {i+1} æ— è¶³å¤Ÿå›¾ç‰‡ï¼ˆéœ€è¦2å¼ ï¼‰")
    
    # ç»Ÿè®¡ä¿¡æ¯
    used_images = image_index
    unused_images = len(image_files) - used_images
    print(f"\nğŸ“Š å›¾ç‰‡ä½¿ç”¨ç»Ÿè®¡:")
    print(f"   æ€»å›¾ç‰‡: {len(image_files)}")
    print(f"   å·²ä½¿ç”¨: {used_images}")
    print(f"   æœªä½¿ç”¨: {unused_images}")
    if unused_images > 0:
        print(f"   â„¹ï¸  å»ºè®®å‡å°‘å›¾ç‰‡æ•°é‡æˆ–å¢åŠ éŸ³é¢‘å†…å®¹")
    
    # 5. åˆæˆè§†é¢‘ï¼ˆé»‘è‰²èƒŒæ™¯ï¼‰
    background = ColorClip(size=(1920, 1080), color=(0, 0, 0), duration=total_duration)
    video = CompositeVideoClip([background] + clips)
    video = video.set_audio(audio)
    
    # 6. æ·»åŠ å­—å¹•
    def subtitle_generator(txt):
        return TextClip(
            txt,
            font='Arial-Bold',        # å­—ä½“
            fontsize=60,              # å­—å·
            color='white',            # å­—ä½“é¢œè‰²
            stroke_color='black',     # æè¾¹é¢œè‰²
            stroke_width=2,           # æè¾¹å®½åº¦
            method='caption',         # è‡ªåŠ¨æ¢è¡Œ
            size=(1800, None)         # å­—å¹•å®½åº¦
        )
    
    subtitles = SubtitlesClip(srt_path, subtitle_generator)
    subtitles = subtitles.set_position(('center', 900))  # åº•éƒ¨ä½ç½®
    
    final_video = CompositeVideoClip([video, subtitles])
    
    # 7. å¯¼å‡ºè§†é¢‘
    print(f"\nğŸ“¹ æ­£åœ¨å¯¼å‡ºè§†é¢‘...")
    final_video.write_videofile(
        output_path,
        fps=30,                # å¸§ç‡
        codec='libx264',       # H.264 ç¼–ç 
        audio_codec='aac',     # AAC éŸ³é¢‘
        preset='medium',       # ç¼–ç é€Ÿåº¦ï¼ˆultrafast/fast/medium/slowï¼‰
        bitrate='5000k'        # ç ç‡
    )
    
    print(f"\nâœ… è§†é¢‘ç”Ÿæˆå®Œæˆï¼")
    print(f"   è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"   åˆ†è¾¨ç‡: 1920x1080 (16:9)")
    print(f"   æ—¶é•¿: {total_duration:.2f}ç§’")


# ============================================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================================

def auto_generate_video(
    input_audio: str,
    image_folder: str,
    output_video: str,
    output_srt: str = "subtitles.srt",
    clean_audio: str = "clean_audio.mp3",
    duration_threshold: float = 1.5
) -> None:
    """
    ä¸€é”®ç”Ÿæˆå£æ’­è§†é¢‘
    
    å®Œæ•´æµç¨‹ï¼š
    1. ç§»é™¤éŸ³é¢‘é™éŸ³ç‰‡æ®µ
    2. è‹±æ–‡è¯­éŸ³è¯†åˆ«
    3. ç”Ÿæˆå­—å¹•æ–‡ä»¶
    4. æ™ºèƒ½åˆ†é…å›¾ç‰‡åˆ°æ—¶é—´çº¿
    5. åˆæˆ16:9è§†é¢‘
    
    Args:
        input_audio: åŸå§‹éŸ³é¢‘è·¯å¾„
        image_folder: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
        output_srt: è¾“å‡ºå­—å¹•è·¯å¾„ï¼ˆé»˜è®¤: subtitles.srtï¼‰
        clean_audio: å¤„ç†åéŸ³é¢‘è·¯å¾„ï¼ˆé»˜è®¤: clean_audio.mp3ï¼‰
        duration_threshold: çŸ­/é•¿éŸ³é¢‘é˜ˆå€¼ï¼ˆé»˜è®¤: 1.5ç§’ï¼‰
    """
    print("=" * 60)
    print("ğŸ¬ æ™ºèƒ½å£æ’­è§†é¢‘è‡ªåŠ¨ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # Step 1: ç§»é™¤é™éŸ³
    clean_audio_path = remove_silence(input_audio, clean_audio)
    
    # Step 2: ç”Ÿæˆå­—å¹•
    segments = generate_subtitles(clean_audio_path, output_srt)
    
    # Step 3: åˆæˆè§†é¢‘ï¼ˆæ™ºèƒ½å›¾ç‰‡åˆ†é…ï¼‰
    create_video_with_smart_distribution(
        audio_path=clean_audio_path,
        image_folder=image_folder,
        srt_path=output_srt,
        output_path=output_video,
        segments=segments,
        duration_threshold=duration_threshold
    )
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("=" * 60)


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    # é…ç½®æ–‡ä»¶è·¯å¾„
    INPUT_AUDIO = "/Users/mac/YouTube/01å·¥å…·ç±»/playwright/input.mp3"
    IMAGE_FOLDER = "/Users/mac/YouTube/01å·¥å…·ç±»/playwright/reference_images/01"
    OUTPUT_VIDEO = "/Users/mac/YouTube/01å·¥å…·ç±»/playwright/output.mp4"
    
    # å¯é€‰å‚æ•°
    OUTPUT_SRT = "/Users/mac/YouTube/01å·¥å…·ç±»/playwright/subtitles.srt"
    CLEAN_AUDIO = "/Users/mac/YouTube/01å·¥å…·ç±»/playwright/clean_audio.mp3"
    DURATION_THRESHOLD = 1.5  # çŸ­/é•¿éŸ³é¢‘é˜ˆå€¼ï¼ˆç§’ï¼‰
    
    # æ‰§è¡Œç”Ÿæˆ
    auto_generate_video(
        input_audio=INPUT_AUDIO,
        image_folder=IMAGE_FOLDER,
        output_video=OUTPUT_VIDEO,
        output_srt=OUTPUT_SRT,
        clean_audio=CLEAN_AUDIO,
        duration_threshold=DURATION_THRESHOLD
    )
```

---

## ğŸ› ï¸ ç¯å¢ƒé…ç½®

### 1. å®‰è£… Python ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–åº“
pip install pydub whisper moviepy mutagen

# å®‰è£… Whisper çš„ä¾èµ–
pip install openai-whisper
```

### 2. å®‰è£… FFmpeg

```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows (ä½¿ç”¨ Chocolatey)
choco install ffmpeg
```

### 3. éªŒè¯å®‰è£…

```bash
# éªŒè¯ FFmpeg
ffmpeg -version

# éªŒè¯ Python åº“
python -c "import whisper; print('Whisper OK')"
python -c "from moviepy.editor import *; print('MoviePy OK')"
python -c "from pydub import AudioSegment; print('Pydub OK')"
```

---

## ğŸ“– ä½¿ç”¨è¯´æ˜

### å¿«é€Ÿå¼€å§‹

```bash
# 1. ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„é…ç½®
INPUT_AUDIO = "ä½ çš„éŸ³é¢‘.mp3"
IMAGE_FOLDER = "ä½ çš„å›¾ç‰‡æ–‡ä»¶å¤¹"
OUTPUT_VIDEO = "è¾“å‡ºè§†é¢‘.mp4"

# 2. è¿è¡Œè„šæœ¬
python auto_video_generator.py
```

### æ–‡ä»¶ç»„ç»‡å»ºè®®

```
é¡¹ç›®æ–‡ä»¶å¤¹/
â”œâ”€â”€ auto_video_generator.py   # ä¸»ç¨‹åº
â”œâ”€â”€ input/                     # è¾“å…¥æ–‡ä»¶
â”‚   â”œâ”€â”€ audio.mp3             # åŸå§‹éŸ³é¢‘
â”‚   â””â”€â”€ images/               # å›¾ç‰‡æ–‡ä»¶å¤¹
â”‚       â”œâ”€â”€ 1.png
â”‚       â”œâ”€â”€ 2.png
â”‚       â””â”€â”€ 3.png
â”œâ”€â”€ output/                    # è¾“å‡ºæ–‡ä»¶
â”‚   â”œâ”€â”€ final_video.mp4       # æœ€ç»ˆè§†é¢‘
â”‚   â”œâ”€â”€ subtitles.srt         # å­—å¹•æ–‡ä»¶
â”‚   â””â”€â”€ clean_audio.mp3       # å¤„ç†åéŸ³é¢‘
â””â”€â”€ README.md
```

### å›¾ç‰‡å‘½åå»ºè®®

```
æ¨èå‘½åæ ¼å¼ï¼ˆè‡ªç„¶æ’åºï¼‰ï¼š
âœ… 1.png, 2.png, 3.png ...
âœ… image_01.png, image_02.png ...
âœ… scene-1.jpg, scene-2.jpg ...

é¿å…çš„å‘½åæ ¼å¼ï¼š
âŒ img1.png, img10.png, img2.png (ä¼šä¹±åº)
```

---

## âš™ï¸ å‚æ•°è°ƒä¼˜

### 1. é™éŸ³æ£€æµ‹å‚æ•°

```python
# åœ¨ remove_silence() å‡½æ•°ä¸­è°ƒæ•´

nonsilent_ranges = detect_nonsilent(
    audio,
    min_silence_len=500,    # è°ƒæ•´è¿™ä¸ªå€¼
    silence_thresh=-40,     # è°ƒæ•´è¿™ä¸ªå€¼
    seek_step=10
)
```

**å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | å»ºè®®å€¼ |
|------|------|--------|
| `min_silence_len` | æœ€å°é™éŸ³é•¿åº¦ï¼ˆmsï¼‰ | 300-800 |
| `silence_thresh` | é™éŸ³é˜ˆå€¼ï¼ˆdBï¼‰ | -50 åˆ° -30 |

**è°ƒä¼˜å»ºè®®ï¼š**
- ğŸ”‡ **é—´éš™å¤ªå¤š**ï¼šå¢å¤§ `min_silence_len`ï¼ˆå¦‚ 800ï¼‰
- ğŸ”Š **åˆ é™¤è¿‡åº¦**ï¼šé™ä½ `silence_thresh`ï¼ˆå¦‚ -50ï¼‰

### 2. çŸ­/é•¿éŸ³é¢‘é˜ˆå€¼

```python
# åœ¨ä¸»å‡½æ•°ä¸­è°ƒæ•´
DURATION_THRESHOLD = 1.5  # ç§’

# è¾ƒæ¿€è¿›çš„åˆ‡æ¢ï¼ˆæ›´å¤šåŒå›¾ï¼‰
DURATION_THRESHOLD = 1.0

# è¾ƒä¿å®ˆçš„åˆ‡æ¢ï¼ˆæ›´å¤šå•å›¾ï¼‰
DURATION_THRESHOLD = 2.0
```

### 3. Whisper æ¨¡å‹é€‰æ‹©

```python
# åœ¨ generate_subtitles() ä¸­è°ƒæ•´
model = whisper.load_model("base")  # æ”¹ä¸ºå…¶ä»–æ¨¡å‹
```

**æ¨¡å‹å¯¹æ¯”ï¼š**

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|------|--------|---------|
| `tiny` | 39MB | æå¿« | â­â­ | æµ‹è¯•ç”¨ |
| `base` | 74MB | å¿« | â­â­â­ | **æ¨è** |
| `small` | 244MB | ä¸­ | â­â­â­â­ | é«˜è´¨é‡ |
| `medium` | 769MB | æ…¢ | â­â­â­â­â­ | ä¸“ä¸šçº§ |

### 4. å­—å¹•æ ·å¼

```python
# åœ¨ subtitle_generator() ä¸­è°ƒæ•´

TextClip(
    txt,
    font='Arial-Bold',         # å­—ä½“
    fontsize=60,               # å­—å·ï¼ˆ40-80ï¼‰
    color='white',             # é¢œè‰²
    stroke_color='black',      # æè¾¹é¢œè‰²
    stroke_width=2,            # æè¾¹å®½åº¦ï¼ˆ1-3ï¼‰
    method='caption',
    size=(1800, None)          # å­—å¹•å®½åº¦
)
```

---

## ğŸš€ è¿›é˜¶åŠŸèƒ½

### æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘

```python
def batch_generate_videos(config_list: List[dict]):
    """
    æ‰¹é‡ç”Ÿæˆå¤šä¸ªè§†é¢‘
    
    Args:
        config_list: é…ç½®åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«:
            - input_audio: éŸ³é¢‘è·¯å¾„
            - image_folder: å›¾ç‰‡æ–‡ä»¶å¤¹
            - output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    for i, config in enumerate(config_list, 1):
        print(f"\n{'='*60}")
        print(f"å¤„ç†ç¬¬ {i}/{len(config_list)} ä¸ªè§†é¢‘")
        print(f"{'='*60}")
        
        auto_generate_video(**config)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    configs = [
        {
            "input_audio": "story1/audio.mp3",
            "image_folder": "story1/images",
            "output_video": "output/story1.mp4"
        },
        {
            "input_audio": "story2/audio.mp3",
            "image_folder": "story2/images",
            "output_video": "output/story2.mp4"
        }
    ]
    
    batch_generate_videos(configs)
```

### æ·»åŠ èƒŒæ™¯éŸ³ä¹

```python
def add_background_music(
    video_path: str,
    music_path: str,
    output_path: str,
    music_volume: float = 0.1  # èƒŒæ™¯éŸ³ä¹éŸ³é‡ï¼ˆ0.0-1.0ï¼‰
):
    """æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
    from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
    
    video = VideoFileClip(video_path)
    original_audio = video.audio
    
    # åŠ è½½èƒŒæ™¯éŸ³ä¹å¹¶å¾ªç¯åˆ°è§†é¢‘æ—¶é•¿
    music = AudioFileClip(music_path).volumex(music_volume)
    music = music.audio_loop(duration=video.duration)
    
    # æ··åˆéŸ³é¢‘
    final_audio = CompositeAudioClip([original_audio, music])
    video = video.set_audio(final_audio)
    
    video.write_videofile(output_path, codec='libx264', audio_codec='aac')
```

### æ·»åŠ è½¬åœºæ•ˆæœ

```python
from moviepy.video.fx.fadein import fadein
from moviepy.video.fx.fadeout import fadeout

# åœ¨åˆ›å»º img_clip æ—¶æ·»åŠ 
img_clip = (ImageClip(img_path)
           .set_start(start_time)
           .set_duration(duration)
           .resize(height=1080)
           .set_position("center")
           .fadein(0.3)   # 0.3ç§’æ·¡å…¥
           .fadeout(0.3)) # 0.3ç§’æ·¡å‡º
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†éŸ³é¢‘ï¼ˆå¤šæ–‡ä»¶ï¼‰

```python
from multiprocessing import Pool

def process_audio_parallel(audio_files: List[str]):
    """å¹¶è¡Œå¤„ç†å¤šä¸ªéŸ³é¢‘"""
    with Pool(processes=4) as pool:
        results = pool.map(remove_silence, audio_files)
    return results
```

### 2. é™ä½è§†é¢‘æ¸²æŸ“æ—¶é—´

```python
# ä½¿ç”¨æ›´å¿«çš„ç¼–ç é¢„è®¾
final_video.write_videofile(
    output_path,
    fps=30,
    codec='libx264',
    preset='ultrafast',  # æ”¹ä¸º ultrafastï¼ˆè´¨é‡ç¨é™ï¼‰
    threads=8            # å¢åŠ çº¿ç¨‹æ•°
)
```

### 3. ç¼“å­˜ Whisper æ¨¡å‹

```python
# å…¨å±€åŠ è½½æ¨¡å‹ï¼Œé¿å…é‡å¤åŠ è½½
WHISPER_MODEL = None

def get_whisper_model():
    global WHISPER_MODEL
    if WHISPER_MODEL is None:
        WHISPER_MODEL = whisper.load_model("base")
    return WHISPER_MODEL
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: `ModuleNotFoundError: No module named 'pydub'`
```bash
# è§£å†³ï¼šå®‰è£…ç¼ºå¤±çš„åº“
pip install pydub
```

### Q2: `RuntimeError: FFmpeg binary not found`
```bash
# è§£å†³ï¼šå®‰è£… FFmpeg
brew install ffmpeg  # macOS
```

### Q3: å­—å¹•ä¸æ˜¾ç¤º
```bash
# æ£€æŸ¥å­—å¹•æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
ls -la subtitles.srt

# æ£€æŸ¥å­—ä½“æ˜¯å¦å­˜åœ¨
# macOS: /Library/Fonts/
# Windows: C:\Windows\Fonts\
```

### Q4: å›¾ç‰‡åˆ†è¾¨ç‡ä¸å¯¹
```python
# åœ¨ä»£ç ä¸­è°ƒæ•´
.resize(height=1080)  # æ”¹ä¸º .resize(width=1920)
```

### Q5: å†…å­˜ä¸è¶³
```python
# å‡å°‘å¹¶å‘å¤„ç†ï¼Œåˆ†æ‰¹å¤„ç†
# æˆ–ä½¿ç”¨æ›´å°çš„ Whisper æ¨¡å‹
model = whisper.load_model("tiny")
```

---

## ğŸ“ˆ åç»­ä¼˜åŒ–æ–¹å‘

### çŸ­æœŸä¼˜åŒ–
- [ ] æ”¯æŒä¸­æ–‡è¯­éŸ³è¯†åˆ«
- [ ] æ·»åŠ è¿›åº¦æ¡æ˜¾ç¤º
- [ ] æ”¯æŒæ›´å¤šè§†é¢‘æ¯”ä¾‹ï¼ˆ9:16ç«–å±ç­‰ï¼‰
- [ ] æ·»åŠ é¢„è§ˆåŠŸèƒ½

### ä¸­æœŸä¼˜åŒ–
- [ ] å›¾å½¢åŒ–ç•Œé¢ï¼ˆGUIï¼‰
- [ ] äº‘ç«¯æ‰¹é‡å¤„ç†
- [ ] AI è‡ªåŠ¨é…å›¾ï¼ˆæ ¹æ®æ–‡æœ¬å†…å®¹ï¼‰
- [ ] å¤šè¯­è¨€å­—å¹•æ”¯æŒ

### é•¿æœŸä¼˜åŒ–
- [ ] Web åœ¨çº¿æœåŠ¡
- [ ] AI é…éŸ³ä¼˜åŒ–
- [ ] æ™ºèƒ½å‰ªè¾‘ï¼ˆåˆ é™¤å£è¯¯ã€é‡å¤ï¼‰
- [ ] è‡ªåŠ¨æ·»åŠ è½¬åœºå’Œç‰¹æ•ˆ

---

## ğŸ“ æ€»ç»“

**æ–¹æ¡ˆ A çš„æ ¸å¿ƒä¼˜åŠ¿ï¼š**

âœ… **å®Œå…¨è‡ªåŠ¨åŒ–** - ä»éŸ³é¢‘åˆ°è§†é¢‘ä¸€é”®ç”Ÿæˆ  
âœ… **æ™ºèƒ½åˆ†é…** - å€Ÿé‰´ zidongjianji.py çš„æˆç†Ÿé€»è¾‘  
âœ… **é«˜è´¨é‡è¾“å‡º** - 16:9 æ ‡å‡†è§†é¢‘ + ç²¾å‡†å­—å¹•  
âœ… **å¯å®šåˆ¶åŒ–** - æ‰€æœ‰å‚æ•°å¯è°ƒæ•´  
âœ… **å¼€æºå…è´¹** - æ— éœ€ä¾èµ–å•†ä¸šè½¯ä»¶

**é€‚ç”¨åœºæ™¯ï¼š**
- ğŸ“¹ YouTube/Bç«™ æ•™è‚²è§†é¢‘
- ğŸ™ï¸ æ’­å®¢è½¬è§†é¢‘
- ğŸ“š æœ‰å£°ä¹¦å¯è§†åŒ–
- ğŸ¬ çŸ­è§†é¢‘æ‰¹é‡ç”Ÿæˆ

**é¢„æœŸæ•ˆæœï¼š**
```
è¾“å…¥: 1åˆ†é’ŸéŸ³é¢‘ + 10å¼ å›¾ç‰‡
å¤„ç†æ—¶é—´: çº¦3-5åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
è¾“å‡º: 
  â”œâ”€â”€ é«˜è´¨é‡ MP4 è§†é¢‘
  â”œâ”€â”€ SRT å­—å¹•æ–‡ä»¶
  â””â”€â”€ å¤„ç†åçš„éŸ³é¢‘
```

---

## ğŸ“ åç»­æ”¯æŒ

å¦‚éœ€è¿›ä¸€æ­¥å®šåˆ¶æˆ–é‡åˆ°é—®é¢˜ï¼š
1. æä¾›éŸ³é¢‘æ ·æœ¬è¿›è¡Œå‚æ•°è°ƒä¼˜
2. æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ä»£ç 
3. æ·»åŠ ç‰¹å®šåŠŸèƒ½éœ€æ±‚

**å¼€å§‹å®æ–½å‰å»ºè®®ï¼š**
1. å…ˆç”¨å°æ ·æœ¬æµ‹è¯•ï¼ˆ10ç§’éŸ³é¢‘ + 3å¼ å›¾ï¼‰
2. éªŒè¯æ•ˆæœåå†æ‰¹é‡å¤„ç†
3. æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´é˜ˆå€¼å‚æ•°

---

*æ–‡æ¡£ç‰ˆæœ¬: 1.0*  
*æœ€åæ›´æ–°: 2025-10-13*

